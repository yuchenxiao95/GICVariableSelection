# GICVariableSelection.jl

Variable selection using Generalized Information Criteria (GIC) in High Dimensions.

[![Stable](https://img.shields.io/badge/docs-stable-blue.svg)](https://your_docs_url)
[![Dev](https://img.shields.io/badge/docs-dev-blue.svg)](https://your_docs_url)
[![Build Status](https://github.com/yuchenxiao95/GICVariableSelection.jl/actions/workflows/CI.yml/badge.svg)](https://github.com/yuchenxiao95/GICVariableSelection.jl/actions)

---

## Overview

This Julia package provides variable selection methods using Generalized Information Criteria (GIC) for high-dimensional data. It supports both univariate and multivariate response settings, with support for standard and structured penalties.

## Features
- Compute AIC, BIC, SIC, and several GIC variants
- GIC-based variable selection
- Simulation utilities for Normal and Multivariate Normal models

## Installation
```julia
pkg> add https://github.com/yuchenxiao95/GICVariableSelection.jl
```

## Usage Examples

### Example 1: Univariate Normal Data
```julia
using GICVariableSelection, Distributions, Random, DataFrames

N, P, k = 1000, 500, 5
rho = 0.0
true_columns = sort(sample(1:P, k, replace=false))
SNR = [0.09, 0.14, 0.25, 0.42, 0.71, 1.22, 2.07, 3.52, 6.00]

mu = zeros(P)
cov = fill(rho, P, P)
for i in 1:P
    cov[i, i] = 1.0
end
X = Matrix(rand(MvNormal(mu, cov), N)')

true_beta = zeros(P)
true_beta[true_columns] .= 2
variance = (true_beta' * cov * true_beta) / SNR[5]
std = sqrt(variance)

Y = LP_to_Y(X, true_beta, family="Normal", std=std)

init_cols  = collect(1:P)
@time begin 
    tmp = GIC_Variable_Selection(X, Y, init_cols, Calculate_BIC, Calculate_BIC_short, Nsim =5)
end
tmp_df = DataFrame(A = tmp[1], 
                   B = tmp[2])
print(setdiff(tmp[2][end], true_columns))
print(setdiff(true_columns, tmp[2][end]))
```

### Example 2: Multivariate Normal Data
```julia
m = 5
multi_beta = zeros(P, m)
multi_beta_true_columns = Vector{Vector{Int}}(undef, m)

for i in 1:m
    cols = sort(sample(1:P, k, replace=false))
    multi_beta_true_columns[i] = cols
    multi_beta[cols, i] .= collect(range(10, 0.1, length=k))
end

variance = (multi_beta' * cov * multi_beta) ./ SNR[5]
cov_p = fill(rho, m, m); for i in 1:m cov_p[i, i] = 1.0 end
Y = LP_to_Y(X, multi_beta, family="MultivariateNormal", cov_matrix=cov_p)

init_cols = collect(1:P)
@time tmp = GIC_Variable_Selection(X, Y, init_cols, Calculate_SIC, Calculate_SIC_short, Nsim=5)

# Summary
tmp_df = DataFrame(A = tmp[1], B = tmp[2])
random_index_true_columns = unique(reduce(vcat, multi_beta_true_columns))
println("False Positives: ", setdiff(tmp[2][end], random_index_true_columns))
println("False Negatives: ", setdiff(random_index_true_columns, tmp[2][end]))


```

## Available Exports
```julia
Calculate_AIC, Calculate_AIC_short,
Calculate_AIC_c, Calculate_AIC_c_short,
Calculate_BIC, Calculate_BIC_short,
Calculate_CAIC, Calculate_CAIC_short,
Calculate_CAICF, Calculate_CAICF_short,
Calculate_SIC, Calculate_SIC_short,
Calculate_AttIC, Calculate_AttIC_short,
Calculate_GIC2, Calculate_GIC2_short,
Calculate_GIC3, Calculate_GIC3_short,
Calculate_GIC4, Calculate_GIC4_short,
Calculate_GIC5, Calculate_GIC5_short,
Calculate_GIC6, Calculate_GIC6_short,
GIC_Variable_Selection, GIC_Variable_Selection_Boltzmann,
Beta_estimate, Y_to_lp, LP_to_Y
```

## License
MIT License. See `LICENSE` file for details.

---

Â© 2025 Yuchen Xiao. All rights reserved.
